<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Internal and External Validity in Health Service Psychology | Transforming Research Methods in Health Services Psychology: Applications for the Advocate ~ Practitioner ~ Scientist</title>
  <meta name="description" content="“Analysis of Variance” is a mini-volume in the ReCentering Psych Stats series that provides workflows and worked examples in R. A core focus of the ReCentering series is simulate data from published examples that recenter psychological research in a socially and culturally responsive manner." />
  <meta name="generator" content="bookdown 0.27 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Internal and External Validity in Health Service Psychology | Transforming Research Methods in Health Services Psychology: Applications for the Advocate ~ Practitioner ~ Scientist" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://lhbikos.github.io/TransformingResearchMethods/images/bookcover.png" />
  <meta property="og:description" content="“Analysis of Variance” is a mini-volume in the ReCentering Psych Stats series that provides workflows and worked examples in R. A core focus of the ReCentering series is simulate data from published examples that recenter psychological research in a socially and culturally responsive manner." />
  <meta name="github-repo" content="lhbikos/ReCenterPsychStats" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Internal and External Validity in Health Service Psychology | Transforming Research Methods in Health Services Psychology: Applications for the Advocate ~ Practitioner ~ Scientist" />
  
  <meta name="twitter:description" content="“Analysis of Variance” is a mini-volume in the ReCentering Psych Stats series that provides workflows and worked examples in R. A core focus of the ReCentering series is simulate data from published examples that recenter psychological research in a socially and culturally responsive manner." />
  <meta name="twitter:image" content="https://lhbikos.github.io/TransformingResearchMethods/images/bookcover.png" />

<meta name="author" content="Lynette H. Bikos, PhD, ABPP &amp; Cirleen DeBlaere, PhD, Editors" />
<meta name="author" content="Kiana Clay, Editorial Assistant" />


<meta name="date" content="2022-07-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="preface.html"/>
<link rel="next" href="OpSci.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Transforming Research Methods in Health Services Psychology: Applications for the Advocate ~ Practitioner ~ Scientist</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>BOOK COVER</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>PREFACE</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#strategies-for-a-social-responsivity"><i class="fa fa-check"></i>Strategies for a Social Responsivity</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#perpetually-in-progress"><i class="fa fa-check"></i>Perpetually in Progress</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#under-construction"><i class="fa fa-check"></i>Under Construction</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#copyright-with-open-access"><i class="fa fa-check"></i>Copyright with Open Access</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="internal-and-external-validity-in-health-service-psychology.html"><a href="internal-and-external-validity-in-health-service-psychology.html"><i class="fa fa-check"></i><b>1</b> Internal and External Validity in Health Service Psychology</a>
<ul>
<li class="chapter" data-level="1.1" data-path="internal-and-external-validity-in-health-service-psychology.html"><a href="internal-and-external-validity-in-health-service-psychology.html#learning-objectives"><i class="fa fa-check"></i><b>1.1</b> Learning Objectives</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="internal-and-external-validity-in-health-service-psychology.html"><a href="internal-and-external-validity-in-health-service-psychology.html#recommended-readings"><i class="fa fa-check"></i><b>1.1.1</b> Recommended Readings</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="OpSci.html"><a href="OpSci.html"><i class="fa fa-check"></i><b>2</b> Open Science as a Step Toward Social Responsivity in Research</a>
<ul>
<li class="chapter" data-level="2.1" data-path="OpSci.html"><a href="OpSci.html#learning-objectives-1"><i class="fa fa-check"></i><b>2.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="2.2" data-path="OpSci.html"><a href="OpSci.html#recommended-readings-1"><i class="fa fa-check"></i><b>2.2</b> Recommended Readings</a></li>
<li class="chapter" data-level="2.3" data-path="OpSci.html"><a href="OpSci.html#defining-open-science"><i class="fa fa-check"></i><b>2.3</b> Defining “Open Science”</a></li>
<li class="chapter" data-level="2.4" data-path="OpSci.html"><a href="OpSci.html#transparency-of-the-research-process"><i class="fa fa-check"></i><b>2.4</b> Transparency of the Research Process</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="OpSci.html"><a href="OpSci.html#preregistration"><i class="fa fa-check"></i><b>2.4.1</b> Preregistration</a></li>
<li class="chapter" data-level="2.4.2" data-path="OpSci.html"><a href="OpSci.html#data-sharing"><i class="fa fa-check"></i><b>2.4.2</b> Data sharing</a></li>
<li class="chapter" data-level="2.4.3" data-path="OpSci.html"><a href="OpSci.html#open-peer-review"><i class="fa fa-check"></i><b>2.4.3</b> Open peer review</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="OpSci.html"><a href="OpSci.html#access-to-the-scientific-literature"><i class="fa fa-check"></i><b>2.5</b> Access to the Scientific Literature</a></li>
<li class="chapter" data-level="2.6" data-path="OpSci.html"><a href="OpSci.html#tools-for-an-open-science"><i class="fa fa-check"></i><b>2.6</b> Tools for an Open Science</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="OpSci.html"><a href="OpSci.html#statistical-software"><i class="fa fa-check"></i><b>2.6.1</b> Statistical Software</a></li>
<li class="chapter" data-level="2.6.2" data-path="OpSci.html"><a href="OpSci.html#reference-management-software"><i class="fa fa-check"></i><b>2.6.2</b> Reference management software</a></li>
<li class="chapter" data-level="2.6.3" data-path="OpSci.html"><a href="OpSci.html#persistent-identifiers"><i class="fa fa-check"></i><b>2.6.3</b> Persistent identifiers</a></li>
<li class="chapter" data-level="2.6.4" data-path="OpSci.html"><a href="OpSci.html#data-repositories"><i class="fa fa-check"></i><b>2.6.4</b> Data repositories</a></li>
<li class="chapter" data-level="2.6.5" data-path="OpSci.html"><a href="OpSci.html#collaborative-platforms"><i class="fa fa-check"></i><b>2.6.5</b> Collaborative platforms</a></li>
<li class="chapter" data-level="2.6.6" data-path="OpSci.html"><a href="OpSci.html#open-education-resources"><i class="fa fa-check"></i><b>2.6.6</b> Open education resources</a></li>
<li class="chapter" data-level="2.6.7" data-path="OpSci.html"><a href="OpSci.html#bearing-the-costs-of-open"><i class="fa fa-check"></i><b>2.6.7</b> Bearing the Costs of “Open”</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="OpSci.html"><a href="OpSci.html#summary-conclusions-andor-recommendations"><i class="fa fa-check"></i><b>2.7</b> Summary, Conclusions, and/or Recommendations</a></li>
<li class="chapter" data-level="2.8" data-path="OpSci.html"><a href="OpSci.html#suggestions-for-practice-further-learning-andor-conversation"><i class="fa fa-check"></i><b>2.8</b> Suggestions for Practice, Further Learning, and/or Conversation</a></li>
<li class="chapter" data-level="2.9" data-path="OpSci.html"><a href="OpSci.html#references"><i class="fa fa-check"></i><b>2.9</b> References</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="writing-empirical-manuscripts.html"><a href="writing-empirical-manuscripts.html"><i class="fa fa-check"></i>WRITING EMPIRICAL MANUSCRIPTS</a></li>
<li class="chapter" data-level="3" data-path="APAstyle.html"><a href="APAstyle.html"><i class="fa fa-check"></i><b>3</b> The APA Style Manuscript</a>
<ul>
<li class="chapter" data-level="3.1" data-path="APAstyle.html"><a href="APAstyle.html#navigating-this-lesson"><i class="fa fa-check"></i><b>3.1</b> Navigating this Lesson</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="APAstyle.html"><a href="APAstyle.html#learning-objectives-2"><i class="fa fa-check"></i><b>3.1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="3.1.2" data-path="APAstyle.html"><a href="APAstyle.html#readings-resources"><i class="fa fa-check"></i><b>3.1.2</b> Readings &amp; Resources</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="APAstyle.html"><a href="APAstyle.html#apa-style-as-epistemology-or-worse"><i class="fa fa-check"></i><b>3.2</b> APA Style as Epistemology (or Worse)</a></li>
<li class="chapter" data-level="3.3" data-path="APAstyle.html"><a href="APAstyle.html#as-we-dive-into-the-specifics"><i class="fa fa-check"></i><b>3.3</b> As We Dive into the Specifics</a></li>
<li class="chapter" data-level="3.4" data-path="APAstyle.html"><a href="APAstyle.html#the-jars-the-core-of-apa-style"><i class="fa fa-check"></i><b>3.4</b> The JARS: The Core of APA Style</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="APAstyle.html"><a href="APAstyle.html#title-authorship-author-note-apa-2.3"><i class="fa fa-check"></i><b>3.4.1</b> Title, Authorship, Author Note (APA 2.3)</a></li>
<li class="chapter" data-level="3.4.2" data-path="APAstyle.html"><a href="APAstyle.html#abstract-apa-2.8-3.3"><i class="fa fa-check"></i><b>3.4.2</b> Abstract (APA 2.8, 3.3)</a></li>
<li class="chapter" data-level="3.4.3" data-path="APAstyle.html"><a href="APAstyle.html#introduction-apa-2.11"><i class="fa fa-check"></i><b>3.4.3</b> Introduction (APA 2.11)</a></li>
<li class="chapter" data-level="3.4.4" data-path="APAstyle.html"><a href="APAstyle.html#method-apa-2.06-chapter-3"><i class="fa fa-check"></i><b>3.4.4</b> Method (APA 2.06; Chapter 3)</a></li>
<li class="chapter" data-level="3.4.5" data-path="APAstyle.html"><a href="APAstyle.html#results-discussion-chapter-3"><i class="fa fa-check"></i><b>3.4.5</b> Results &amp; Discussion (Chapter 3)</a></li>
<li class="chapter" data-level="3.4.6" data-path="APAstyle.html"><a href="APAstyle.html#headings-apa-2.7"><i class="fa fa-check"></i><b>3.4.6</b> Headings (APA 2.7)</a></li>
<li class="chapter" data-level="3.4.7" data-path="APAstyle.html"><a href="APAstyle.html#reference-list"><i class="fa fa-check"></i><b>3.4.7</b> Reference List</a></li>
<li class="chapter" data-level="3.4.8" data-path="APAstyle.html"><a href="APAstyle.html#stylistic-issues-apa-chapter-4-on-writing-style-and-grammar"><i class="fa fa-check"></i><b>3.4.8</b> Stylistic Issues (APA Chapter 4 on <em>Writing Style and Grammar</em>)</a></li>
<li class="chapter" data-level="3.4.9" data-path="APAstyle.html"><a href="APAstyle.html#reducing-bias-apa-chapter-5"><i class="fa fa-check"></i><b>3.4.9</b> Reducing Bias (APA Chapter 5)</a></li>
<li class="chapter" data-level="3.4.10" data-path="APAstyle.html"><a href="APAstyle.html#closing-thoughts"><i class="fa fa-check"></i><b>3.4.10</b> Closing Thoughts</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Transforming Research Methods in Health Services Psychology: Applications for the Advocate ~ Practitioner ~ Scientist</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="internal-and-external-validity-in-health-service-psychology" class="section level1 hasAnchor" number="1">
<h1><span class="header-section-number">Chapter 1</span> Internal and External Validity in Health Service Psychology<a href="internal-and-external-validity-in-health-service-psychology.html#internal-and-external-validity-in-health-service-psychology" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<center>
<em>Franco Dispenza, PhD &amp; Alec Prince, MPA</em><br />
<em>Georgia State University</em><br />
Chapter Status: Under Review
</center>
<p><br></p>
<p>The focus of this lesson is to provide a review of internal validity, external validity, threats to validity, and current trends and considerations in relation to validity. Internal and external validity are foundational to experimental and quasi-experimental research. In experimental and quasi-experimental research designs, health service psychologists work thoughtfully and diligently to ensure that a line of systematic inquiry demonstrates some degree of internal and external validity. This is because psychologists and behavioral health researchers are concerned with making reasonable epistemological claims that could directly impact the lives of diverse communities and populations, especially in research studies attempting to show if particular interventions, treatments, or programs have a true effect on specific outcomes.</p>
<p>Whereas researchers utilizing qualitative frameworks may be more interested in methodological integrity (e.g., credibility and transferability; Levitt et al., 2017), researchers employing quantitative-based paradigms are especially interested in internal and external validity. You will notice that the term “validity” is used in many concepts and research frameworks, including construct validity, content validity, predictive validity, criterion validity, and statistical conclusion validity. These are all specific types of validity attempting to establish a degree of accuracy or truthfulness in research. Further, the aforementioned forms of validity often have statistical computations and procedures that accompany them (e.g., bivariate correlations, beta weights, etc.). This chapter will not address those forms of validity. Instead, we will focus on internal and external validity, conceptual constructs that rely on methodological procedures and considerations versus statistical calculations.</p>
<div id="learning-objectives" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">1.1</span> Learning Objectives<a href="internal-and-external-validity-in-health-service-psychology.html#learning-objectives" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Learning objectives for this chapter include the following:</p>
<ul>
<li>Students will be able to explain the dimensional features of internal and external validity in experimental and quasi-experimental research.
*Students will be able to list and discuss threats associated with internal and external validity in experimental and quasi-experimental research.</li>
<li>Students will be able to discuss and apply established methods for controlling the various threats associated with internal and external validity in experimental and quasi-experimental research.</li>
<li>Students will be able to identify and apply their knowledge of internal validity, external validity, and their associated threats to current trends and issues in psychological research.</li>
<li>Students will be able to critique and distinguish the strengths and limitations of internal and external validity when applied to socially responsive research.</li>
</ul>
<div id="recommended-readings" class="section level3 hasAnchor" number="1.1.1">
<h3><span class="header-section-number">1.1.1</span> Recommended Readings<a href="internal-and-external-validity-in-health-service-psychology.html#recommended-readings" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The following served as critical references in the development of this chapter. We encourage you to review them.</p>
<ul>
<li><p>Campbell, D. T., &amp; Stanley, J. C. (1963). Experimental and quasi- experimental designs for research. Chicago, IL: Rand McNally.</p></li>
<li><p>This classic and foundational text introduces readers to internal validity, external validity, and threats to validity as originally proposed by Campbell and Stanley. It also provides readers with an overview of the various experimental and quasi-experimental methodological designs, and how various methodological designs could be used to minimize threats to validity.</p></li>
<li><p>Ferguson L. (2004). External validity, generalizability, and knowledge utilization. Journal of Nursing Scholarship, 36(1), 16-22. <a href="https://doi.org/10.1111/j.1547-5069.2004.04006.x" class="uri">https://doi.org/10.1111/j.1547-5069.2004.04006.x</a></p></li>
<li><p>Although aimed for a nursing audience, there is much to be gained from Ferguson’s (2004) review of external validity, generalizability, and evidence-based practice. Ferguson reviews much of the major conceptual tenets of external validity, including its threats and control strategies. Ferguson also discusses ways in which researchers and practitioners could enhance external validity of research.</p></li>
<li><p>Schmuckler, M.A.(2001).What Is Ecological Validity? A Dimensional Analysis. Infancy, 2(4), 419-436. <a href="https://doi.org/10.1207/S15327078IN0204_02" class="uri">https://doi.org/10.1207/S15327078IN0204_02</a></p></li>
<li><p>Schmuckler (2001) introduces readers to a subset of external validity, namely ecological validity. Schmuckler provides an historical review of ecological validity, and a discussion of the various dimensions, advantages, and criticisms of ecological validity.</p></li>
</ul>
<center>
<p><strong>Internal Validity</strong></p>
<p>Health service psychologists are committed to accuracy, honesty, and truthfulness when engaging in the research process. Whether representing research findings fairly, capturing the essence of people’s lived experiences with precision, or using research to advocate against harmful psychological practices, researchers are compelled to uphold the integrity of the knowledge claims they make through their scholarship. Researchers are committed to ensuring that their research is justifiable, well-grounded, and internally valid.</p>
<p><em>Internal validity</em> is the extent to which a researcher can infer cause-effect relationships between a set of variables, while simultaneously excluding the influence of confounding or extraneous variables (Campbell &amp; Stanley, 1963; Cook &amp; Campbell, 1979). In an attempt to establish internal validity, it is important to rule out the effects of confounding or extraneous variables. <em>Confounding or extraneous variables</em> can serve as potential rivals to inferred relationships, leading a researcher to be less confident about the conclusions and implications that can be made between an independent (or treatment) variable and a dependent (or outcome) variable.</p>
<p><em>Methodological control</em> is also paramount in experimental and quasi-experimental research. In an ideal research scenario, a researcher will have identified and controlled for all possible confounds and extraneous variables that may be inherent in the methodological design of a study. Since determining causality is the goal in experimental and quasi-experimental research, such a scenario would render a study to be high in internal validity. However, we know in practice there is no such thing as a perfect study, especially when there exist numerous <em>threats to internal validity</em>. Threats consist of factors or conditions that endanger a researcher’s capacity to amplify a study’s level of internal validity (Onwuegbuzie &amp; McLean, 2003).</p>
<p><em>Threats to Interal Validity</em>
Researchers often execute considerable forethought when identifying and eliminating potential threats to internal validity. Psychological researchers are encouraged to use a variety of logic-informed heuristics, “what if” sensitivity analyses, or consider any new data or findings to rule out rival hypotheses (Kenny, 2019). Researchers are also encouraged to consider more classically identified threats to their research design (Campbell &amp; Stanley, 1963). Some of the most common threats to internal validity consist of history, maturation, instrumentation, statistical regression, selection, attrition, and experimenter bias (Campbell &amp; Stanley, 1963; Cook &amp; Campbell, 1979; Shadish et al., 2002). Threats to internal validity can occur, or be discovered, at any point during the research process, including design, implementation, data collection, and analyses. There can exist multiple threats in a given study, and these threats can also intersect with one another. Keep in mind that threats are never something a researcher just “checks off” in a box, but rather a researcher continuously monitors their methods to ensure the credibility of the concluded findings (Onwuegbuzie &amp; McLean, 2003). Each threat to internal validity is discussed in more detail below.</p>
<p><strong>History.</strong> No researcher can control the potential of geological, sociopolitical, financial, cultural, climate-related, pandemic, and other national and global events from impacting individuals in a research study. But inevitably such events happen, and unfortunately with what seems to be at higher frequencies these days. Historical events can influence the manner in which participants respond to a study’s dependent variable, making it difficult for researchers to determine whether an observed outcome was the result of a study’s independent variable or the historical event. In some instances, the historical event could directly intersect with objectives of the study itself making it even more difficult for researchers to make valid conclusions. Imagine you are evaluating the effectiveness of a new stress-reduction intervention for survivors of catastrophic hurricanes in a low-income, rural community in the southeast United States. In the middle of implementing the intervention, a tornado hits the same community, leading to severe damage and loss of life. What impact will this historical event have on the research study?</p>
<p><strong>Maturation.</strong> Development and growth are natural processes that occur for individuals during their lifespan. These processes could be physiological, cognitive, social, or emotional. Given the length of a particular study, sometimes results from a study may be more indicative of naturally occurring growth and developmental factors, versus any manipulated independent variable.</p>
<p><strong>Instrumentation.</strong> No tool, test, or measure used in research can be entirely valid and reliable one hundred percent of the time. Instruments can produce low reliability scores or even produce inadequate psychometric properties (e.g., construct and predictive validity) with a study’s particular sample. This is an important consideration as some tests and measures were never validated or normed with diverse samples. Consider a measure of marital satisfaction that was created using heterosexual couples in the Netherlands. The measure may have great face validity, and even demonstrate adequate levels of content, criterion, and construct validity. But it may not produce the same psychometrics if used in married couples in the United States. It may be entirely inappropriate to use this measure if the United States sample also includes same-sex couples. Lastly, human beings administering instruments could contribute additional error, making instrumentation a serious threat to research studies. For example, some researchers may become fatigued when administering some measures, may not be consistent with measurement, or may not accurately observe a phenomenon during a research study.</p>
<p><strong>Testing.</strong> It is common to test participants multiple times throughout the course of a research study. Researchers often use the same test, measure, scale, or inventory when testing participants, but it begs the question as to whether changes in a test—that had been given multiple times—reflect true change? Sometimes referred to either as a <em>practice effect</em> or <em>fatigue effect</em>, changes in scores on the same test may be the result of familiarity with the test or becoming tired with the test.</p>
<p><strong>Statistical Regression, or Regression to the Mean.</strong> Sometimes researchers select participants based on high or low scores on a particular test or measure (Campbell &amp; Kenny, 1999). For example, researchers may be interested in examining people who score high on measures of academic or cognitive functioning. If retested, those same participants may continue to score high or low. However, not all would score as high or low because of statistical regression, or regression to the mean. When participants are retested, researchers find that scores are less extreme and center toward an average score. Imagine a researcher was interested in testing a career counseling intervention with first generation college students who reported high scores on career indecision and anxiety in a career battery of questionnaires. After the intervention is complete, the researchers issue a final battery of questionnaires. These same first generation college students may appear less anxious and indecisive due to statistical regression to the mean and not necessarily the intervention.</p>
<p><strong>Attrition, of Differential Mortality.</strong> Ethically, participants have the right to withdraw from participating in a research study at any given time during the research process. When participants withdraw, or drop from a study, researchers refer to this as attrition. A major concern of attrition is that it leads to potential biases in scores between groups (or observations in the case of longitudinal studies) that may not reflect whether an independent variable had any effect on the dependent variable. If there is substantial attrition in one group, or across the entire study, it leads a researcher to question why participants are withdrawing. Researchers may further wonder if participants dropping from the study are characteristically different from those who are remaining in the study. Attrition limits the type of conclusions that can be made because observations made across time or between groups may not reflect true differences as a function of the independent variable. Rather, there may be some other underlying issue with the research study.</p>
<p>Imagine a researcher has been evaluating the effects of a six-session mindfulness cognitive behavioral group intervention for the reduction of race related stress among Black and African American women employed in a large healthcare setting. The researcher used a longitudinal, between group experimental design with an intervention group (treatment) and a control group (education), but found that attrition rates were higher for those in the control than for the intervention group. Equivalent and adequate comparisons could not be reliably made between the two groups at completion of study, so the researcher decided to send surveys to those dropped from the study and inquire why they dropped. The surveys return and the researcher finds that a significant portion of the control group were made up of on-call, ambulatory nurses who were unable to commit to the scheduled sessions. Therefore, the attrition was the result of some characteristic that differentiated the two groups.</p>
<p><strong>Experimenter Bias.</strong> Researchers need to ensure they do not engage in verbal or nonverbal behaviors that inadvertently alter the results of a study. Sometimes this is referred to as an <em>experimenter expectancy</em>, and it is even known as the <em>Rosenthal Effect</em>. This becomes a threat when a participant’s response in a study is the result of the experimenter’s expectations versus the manipulated or independent variable. Examples include emphasizing particular words when reading prompts or scripts, or excessive nodding and smiling when certain favorable responses are solicited by study participants.</p>
<p><strong>Selection Bias.</strong> Differences between groups in experimental studies can sometimes be the result of characteristics of the participants themselves, versus the manipulated or independent variable. For instance, a researcher may have accidentally grouped people along the same characteristic, such as sex, gender, sexual orientation, race, ethnicity, or age group. This potentially sets up nonequivalent groups in experimental or quasi-experimental research, and makes it difficult for researchers to determine whether any changes in dependent or outcome variables were the result of an independent variable or the characteristic itself. This also pertains to self-selection bias commonly seen in survey and questionnaire research, in which participants self-select to participate in a study.</p>
<p><em>Controlling for Threats to Internal Validity</em>
Researchers have identified a number of methodological procedures that could be used to control for threats to internal validity (Campbell &amp; Stanley, 1963; Cook &amp; Campbell, 1979; Fabrigar et al., 2020; Onwuegbuzie &amp; McLean, 2003; Shadish et al., 2002). Below we discuss the importance of considering control groups, random assignment, matching, blocking and holding variables constant.</p>
<p><strong>Control Groups.</strong> Control groups are commonly used in experimental and quasi-experimental human subjects research, and there is an important logic to its use. Individuals are assigned to a group (or condition) in which they do not receive the treatment or manipulated variable. However, participants do partake in similar tasks and conditions (e.g., complete surveys, questionnaires, physiological markers, etc.) as those in the experimental condition. Upon completion of the study, researchers then compare how the intervention or experimental condition performed alongside the control condition or group. Control groups are particularly effective at controlling for the effects of history, maturation, testing, instrumentation, and regression toward the mean (Campbell &amp; Stanley, 1963; Cook &amp; Campbell, 1979).</p>
<p><strong>Random Assignment.</strong> Considered one of the most robust methods to control against threats to internal validity, researchers randomly place volunteer participants in various study conditions at the very beginning of a research study. This assures the researcher that each participant had the same or equally probable chance of being placed in either an experimental condition (or group) or a control condition (or group), while helping to decrease any unknown or intentional influence on assignment of participants to different groups. It further assures the researcher that the groups are equitable in terms of various characteristics of the participants (e.g., demographics, temperament, etc.; Fabrigar et al., 2020). Any observed differences or changes seen among the groups or conditions could then be accounted for by the manipulated independent variable or the applied intervention. More importantly, any observed difference between the groups is not the result of any sort of systematic bias that might have occurred during the initial phases of the research study.</p>
<p>Take a hypothetical scenario in which a researcher is evaluating the ways in which implicit sexist messaging influences women’s responses to a cognitive motor task. Women are recruited from the community to participate in the study. One group receives the implicit sexist messaging while the other group does not. However, nearly all members in one group happened to be women between the ages of 21 and 29, while the majority of those in another group were women between the age of 43 and 56 This could constitute a systematic bias since there are generational differences between members in one group versus the other. Random assignment is incredibly important when controlling for the effects of selection (Campbell &amp; Stanley, 1963; Cook &amp; Campbell, 1979; Shadish et al., 2002).</p>
<p>It is important to keep in mind that random assignment and random sampling are not synonymous with one another. <em>Random sampling</em> is when researchers utilize a variety of probable sampling techniques (e.g., simple, systematic, stratified, or cluster) to recruit participants who approximate the general population. It also means that all members of a given population have an equal chance of being recruited to participate.</p>
<p><strong>Matching.</strong> To further avoid the threat of selection bias, researchers may engage in the process of participant matching. This is especially helpful if a researcher cannot guarantee equivalent groups through randomization, or when sample size may be too small. Participants are matched on a variety of characteristics (e.g., cognitive or intelligence pre-test scores, gender, age, etc.), by placing members of similar characteristics in either an experimental/intervention condition or in the control condition. This helps a researcher establish some degree of equivalence between groups within a particular sample.</p>
<p><strong>Blocking and Holding Variables Constant.</strong> Researchers may also choose to use some characteristic in the study’s sample (e.g., cognitive or intelligence scores, ethnicity or race) as an additional independent variable. This is referred to as <em>blocking</em>. Unlike matching, researchers may employ this strategy to see if a particular characteristic of the sample has an effect on the dependent variable. Alternatively, some researchers may choose to hold a particular characteristic constant or homogenize some sample characteristic so as to eliminate any undue influence from extraneous characteristics of a sample. For instance, a researcher may choose to only recruit high school aged adolescent boys between the ages of 14 and 15 who score above a certain threshold on an anxiety and depression measure to participate in a short-term emotional regulation treatment study.</p>
<center>
<p><strong>Extenal Validity</strong></p>
<p>Many researchers invest time and resources with the hopes of expanding their research findings to larger communities and contexts, especially if the research is aimed at alleviating any suffering or influence larger systemic change efforts. Thus, researchers are not only concerned with internal validity, but also the external validity of their study. <em>External validity</em> is the degree towhich research findings can be generalized to the population that approximate the original context of the study (Campbell &amp; Stanley, 1963; Cook &amp; Campbell, 1979; Shadish et al., 2002).</p>
<p>External validity is also concerned with the degree in which a study can be generalized across broader populations, treatments, settings, and conditions (Ferguson, 2004). Researchers wish to move beyond the controlled setting in which the study originally took place, and further consider ways that the findings may apply in other diverse applicational settings, time, persons, or slightly different variables or targets (Kenny, 2019; Shadish et al., 2002). For instance, a researcher who evaluated the effectiveness of a minority stress reduction intervention for transgender and gender nonbinary individuals in a controlled laboratory setting at a university, might have interest in seeing the intervention applied or replicated with transgender and gender nonbinary individuals in community based clinics, private practices, college counseling centers, and other agencies across the United States. That same researcher may have further interest in having their research used to inform policy on affirming psychological care for transgender and gender nonbinary individuals for all mental health practitioners.</p>
<p>Researchers always have the hope that the finding of their research will have some degree of relevance and importance in “real-world” settings, particularly if study findings are replicated in other contexts. Replicated studies that support original study findings are considered to demonstrate high levels of external validity, as well as other forms of validity (e.g., internal validity, construct validity; Fabrigar et al., 2020). As a variation, or subcategory of external validity, ecological validity is concerned with whether a study’s results can be applied to naturalistic or representative settings in every-day life (Andrade, 2018; Schmuckler, 2001). With this in mind, it is important to consider that there also exist threats that could interfere with a researcher’s confidence in the external validity of their study’s findings.</p>
<p><em>Threats to External Validity</em></p>
<p>Campbell and Stanley (1963) identified four particular threats, including reactive or interaction effects of testing, interaction effects of selection bias, reactive effects of arrangement, and multiple treatment interference.</p>
<p><strong>Reactive or Interaction Effect of Testing.</strong> Sometimes researchers need to be cognizant that research studies, experiments, and testing procedures—in and of themselves—may be the catalyst producing some of the findings we see from research. In many “real-world” conditions, people are not tested or observed as much as they are in research. In particular, Campbell and Stanley (1963) discussed how exposure to a pre-test condition, or multiple testing conditions, may influence a study participant’s degree of sensitivity to the experimental variable. Consider an example in which a researcher is interested in examining a clinical supervisor’s attitudes toward racial and ethnic microaggressions in counseling. The clinical supervisor is asked to view a fictitious counseling session of a supervisee, and then asked to identify any subtle instances of discrimination from a 10 minute clip of a counseling session. Afterwards, the researcher follows up with another post-test to see if there have been any changes in attitudes toward racial and ethnic microaggressions in counseling. The potential threat to external validity in this example is that the clinical supervisors in the study have been sensitized by the pre-test condition (i.e., the fictitious counseling session), increasing their potential chances of identifying microaggressions in a counseling session. If generalized out, clinical supervisors may not respond the same way since they’ve not been pre-tested and sensitized.</p>
<p><strong>Interaction Effects of Selection Bias.</strong> Health service psychologists pay close attention to samples, and work diligently to recruit adequate samples to participate. However, there are situations in which a particular sample in a research study would not generalize to the entire population. This could be the result of selection bias. For instance, many university researchers utilize an undergraduate psychology research pool to recruit participants for their research. But undergraduate students represent a biased sample, and do not reflect the larger population in terms of representative demographics. Thus, researchers replicating a study with a different sample may not obtain the same findings.</p>
<p><strong>Reactive Effects of Experimental Arrangements.</strong> Research conducted in highly controlled settings (e.g., sterile laboratories) run the risk of not generalizing well in “real world” diverse settings or populations. This is mainly to do with the fact that research participants are willing volunteers who understand they are fully participating in experimental or study-related activities. In some instances, research participants may respond or behave a certain way because they are being observed. Frey (2018) reports that a participant may even have the desire to please a researcher by altering their performance on a particular outcome. This may sound familiar because you may understand this to be the <em>Hawthorne effect</em>, a phenomenon in which human beings change their behavior as a result of being observed.</p>
<p><strong>Multiple Treatment Interference.</strong> Depending on the sequencing of a particular study, researchers may provide the same subject different treatments or interventions at different intervals. For example, a researcher may be testing multiple formats to examine the combination of psychotropic medication along with some type of psychotherapy. However, this makes it difficult for researchers to determine if the sequencing of the differing treatments played any role in any of the observed outcomes. Because of this type of sequencing, we would argue that there has been some level of treatment contamination, because it is difficult to control effects from previous treatments or studies.</p>
<p><em>Controlling for Threats to External Validity</em></p>
<p>It is important to note that external validity can never be assured, even when a researcher stringently addresses and controls for threats to internal validity (Ferguson, 2004). However, there are some threats to external validity that can be managed through some methodological considerations. Below we discuss only a few, including random selection, concealed research, as well as counterbalancing and strategies to control for pre-testing effects.</p>
<p><strong>Random Selection.</strong> Sometimes confused with random assignment (already discussed above as a means of controlling threats to internal validity), random selection is about accessing and including a representative sample of the target population in a research study. Random sampling procedures, such as simple or stratified sampling, play a significant role when it comes to random selection. You may recall that random sampling is concerned with the notion that every individual (or observation) has an equal probability of being selected for a study. The equal probability of being selected then increases the probable chances that research findings can be generalized back to the target population (Ferguson, 2004). This form of control is particularly beneficial when considering the interaction effects of selection bias.</p>
<p><strong>Single, Double, and Triple-Concealed Research.</strong> It is important to preface that the term often used in research texts is single, double, and triple “blind” research. However, we believe “blind” is often misused in a variety of contexts, and in this context we believe it perpetuates ableist ideologies. And so, we offer a slight modification by using the term “concealed.” In order to reduce overt and covert forms of researcher bias in a study, researchers attempt to conceal as much as possible from participants and other members of a research team. In a single-concealed research study, only the researcher knows if participants are in a control or experimental group. Participants do not know what condition they are in. In a double-concealed research study, neither the researcher or participant know which is the control or experimental group. In a triple-concealed research study, consistent with the double-concealed design, neither the researcher nor participant know if they are in the control or experimental group. Additionally, those responsible for analyzing or examining outcomes do not know which set of variables were the control or experimental condition. This form of control is especially helpful when addressing reactive effects of experimental arrangements.</p>
<p><strong>Counterbalancing and Controlling for Pre-Test Effects.</strong> In order to address the effects of multiple treatment interference, or carryover effects, a researcher may consider the use of counterbalancing. A researcher must decide <em>a priori</em> all the possible sequences for a treatment, implement those varying permutations, and evaluate study participants in those different orders in order minimize carryover effects. If pre-testing effects is a concern, a researcher may decide not to include a pre-test at all, and compare groups at post-test only. Relatedly, a researcher may want to consider the use of the <em>Solomon Four-Group Design</em> as a means of countering the effects of a pre-test (Allen, 2017). In a Solomon Four-Group Design, a researcher will have four groups, in which some groups receive a pre-test and other groups do not.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="preface.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="OpSci.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["TransformingResearchMethods.pdf", "TransformingResearchMethods.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
